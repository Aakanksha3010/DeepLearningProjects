{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import *\n",
    "import hyperopt\n",
    "from hyperopt import *\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Loading the data: </b> We will load the data for analysis here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       140.562500   \n",
       "1                       102.507812   \n",
       "2                       103.015625   \n",
       "3                       136.750000   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      55.683782   \n",
       "1                                      58.882430   \n",
       "2                                      39.341649   \n",
       "3                                      57.178449   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                   -0.234571   \n",
       "1                                    0.465318   \n",
       "2                                    0.323328   \n",
       "3                                   -0.068415   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.699648                   3.199833   \n",
       "1                            -0.515088                   1.677258   \n",
       "2                             1.051164                   3.121237   \n",
       "3                            -0.636238                   3.642977   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                19.110426   \n",
       "1                                14.860146   \n",
       "2                                21.744669   \n",
       "3                                20.959280   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.975532                      74.242225   \n",
       "1                             10.576487                     127.393580   \n",
       "2                              7.735822                      63.171909   \n",
       "3                              6.896499                      53.593661   \n",
       "\n",
       "   target_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_of_input_file = 'D:\\\\kaggle_trials\\\\predicting-a-pulsar-star\\\\pulsar_stars.csv'\n",
    "df                 = pd.read_csv(path_of_input_file)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive examples are :-  1639\n",
      "The number of negative examples are :-  16259\n"
     ]
    }
   ],
   "source": [
    "print('The number of positive examples are :- ',len(df[df['target_class']==1]))\n",
    "print('The number of negative examples are :- ',len(df[df['target_class']==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Resampling to remove model imbalance:</b> We can clearly see from the above block that the number of negative samples are way higher than the number of positive samples. So we will create synthetic data to balance the dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X            = df[df.columns[:-1]].values\n",
    "Y            = df['target_class'].values\n",
    "sm           = SMOTE(random_state=42)\n",
    "X_res, Y_res = sm.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Data After Resampling :</b> We can clearly see the data after and before resampling. Now we can say that the data is balanced and we will use this data for further analysis\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples before Oversampling is  1639\n",
      "Negative examples before Oversampling is  16259\n",
      "\n",
      "\n",
      "Positive examples after Oversampling is  16259\n",
      "Negative examples after Oversampling is  16259\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Positive examples before Oversampling is ', sum(Y == 1))\n",
    "print('Negative examples before Oversampling is ', sum(Y == 0))\n",
    "print('\\n')\n",
    "print('Positive examples after Oversampling is ', sum(Y_res == 1))\n",
    "print('Negative examples after Oversampling is ', sum(Y_res == 0))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Train Test Split:</b> We will perform train test split of the data from the last step\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, Y_res, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Parameter Grid:</b> We will create a grid for the parameters to be used for parameter tuning. There will be some discrete choices and there will be some continuous choices and hyperopt will iterate through each of the choices and find the optimal solution for us\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 200/200 [05:58<00:00,  1.60s/it, best loss: -0.9574975922336885]\n",
      "The best parameter tuned on training set is given by :-  {'learning_rate': 0.6614693331752434, 'loss': 1, 'max_depth': 6, 'max_features': 2, 'max_leaf_nodes': 6, 'min_samples_leaf': 7, 'min_samples_split': 0.049360178427083734, 'n_estimators': 29, 'subsample': 0.9997382162423892}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameter_grid_gbm = {\n",
    "    'n_estimators' : hp.choice('n_estimators',range(100,150)),\n",
    "    'learning_rate': hp.uniform('learning_rate',0.01,0.99),\n",
    "    'loss'         : hp.choice('loss',['deviance','exponential']),\n",
    "    'subsample'    : hp.uniform('subsample',0.05,1.0),\n",
    "    'min_samples_split' : hp.uniform('min_samples_split',0.02,1.0),\n",
    "    'min_samples_leaf'  : hp.choice('min_samples_leaf',range(1,10)),\n",
    "    'max_depth'         : hp.choice('max_depth',range(3,10)),\n",
    "    'max_features'      : hp.choice('max_features',['auto','sqrt','log2']),\n",
    "    'max_leaf_nodes'    : hp.choice('max_leaf_nodes',range(2,10))\n",
    "}\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best_parameters = fmin(function_to_minimise, parameter_grid_gbm, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Instantiating a GBM model:</b> We will instantiate a GBM classifier based on the parameters attained above and we will fit it on the training data. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.6614693331752434, loss='deviance',\n",
       "                           max_depth=6, max_features=2, max_leaf_nodes=6,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=7,\n",
       "                           min_samples_split=0.049360178427083734,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=29,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=0.9997382162423892,\n",
       "                           tol=0.0001, validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbmclf = GradientBoostingClassifier(learning_rate     = best_parameters['learning_rate'],\n",
    "                                    loss              = 'deviance',\n",
    "                                    max_depth         = best_parameters['max_depth'],\n",
    "                                    max_features      = best_parameters['max_features'],\n",
    "                                    max_leaf_nodes    = best_parameters['max_leaf_nodes'],\n",
    "                                    min_samples_leaf  = best_parameters['min_samples_leaf'],\n",
    "                                    min_samples_split = best_parameters['min_samples_split'],\n",
    "                                    n_estimators      = best_parameters['n_estimators'],\n",
    "                                    subsample         = best_parameters['subsample'])\n",
    "gbmclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Predicting results:</b> GBM classifier trained above will predict the results and we will then analyse the classification report based on the test data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      5539\n",
      "           1       0.93      0.96      0.95      5192\n",
      "\n",
      "    accuracy                           0.95     10731\n",
      "   macro avg       0.95      0.95      0.95     10731\n",
      "weighted avg       0.95      0.95      0.95     10731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = gbmclf.predict(X_test)\n",
    "print(classification_report(y_hat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
