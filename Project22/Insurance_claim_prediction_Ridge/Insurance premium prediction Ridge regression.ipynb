{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import *\n",
    "import hyperopt\n",
    "from hyperopt import *\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Loading the data:</b> We load the data from the mentioned path\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.8</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex   bmi  children smoker     region  expenses\n",
       "0   19  female  27.9         0    yes  southwest  16884.92\n",
       "1   18    male  33.8         1     no  southeast   1725.55\n",
       "2   28    male  33.0         3     no  southeast   4449.46\n",
       "3   33    male  22.7         0     no  northwest  21984.47"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_of_input_file = r'D:\\kaggle_trials\\insurance-premium-prediction\\insurance.csv'\n",
    "df                 = pd.read_csv(path_of_input_file)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Categorical and Numerical Columns Identification:</b> We identify categorical and numerical columns from the data. We do set a threshold that if any categorical value is classified as numerical, then it has to be classified back to categorical if the number of distinct values of that column in the dataframe is less than 10 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_needed           = list(df.columns)\n",
    "cols_needed           = cols_needed[:len(cols_needed)-1]\n",
    "\n",
    "possible_numeric_cols = list(df._get_numeric_data().columns)\n",
    "possible_numeric_cols.remove('expenses')\n",
    "\n",
    "categorical_columns   = list(set(cols_needed)- set(possible_numeric_cols))\n",
    "\n",
    "numerical_columns     = []\n",
    "for i in range(len(possible_numeric_cols)):\n",
    "    col_name  = possible_numeric_cols[i]\n",
    "    if len(df[col_name].unique())<10:\n",
    "        categorical_columns.append(col_name)\n",
    "    else:\n",
    "        numerical_columns.append(col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Missing Value Treatment:</b> We impute the categorical missing values with their mode and the numerical missing values with their mean\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(categorical_columns)):\n",
    "    df[categorical_columns[i]] = df[categorical_columns[i]].fillna(df[categorical_columns[i]].mode()[0])\n",
    "mean_impute_dict    ={}\n",
    "for i in range(len(numerical_columns)):\n",
    "    mean_impute_dict[numerical_columns[i]] = np.nanmean(np.float_(df[numerical_columns[i]].values))\n",
    "for i in range(len(numerical_columns)):\n",
    "    df[numerical_columns[i]]   = df[numerical_columns[i]].fillna(mean_impute_dict[numerical_columns[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Encoding and Feature Scaling:</b> We do the one hot encoding of categorical values and scale(by using MinMaxScaler) the numerical values to get the final feature matrix X. Subseqently, we consider the SalePrice column to be our target variable\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe                  = OneHotEncoder()\n",
    "scalar               = MinMaxScaler()\n",
    "encoded_matrix       = ohe.fit_transform(df[categorical_columns])\n",
    "scaled_matrix        = scalar.fit_transform(df[numerical_columns])\n",
    "X_complete_matrix    = scipy.sparse.hstack((encoded_matrix,scaled_matrix)).A\n",
    "Y                    = scalar.fit_transform(df[['expenses']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Train Test split:</b> We perform train test split on the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_complete_matrix, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ridge Regressor parameters:</b> We specify ridge regressor parameters here to hypertune them\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_grid  = {'alpha' : hp.uniform('alpha',0.01,5),\n",
    "                      'solver'          : hp.choice('solver',['auto','svd','cholesky','lsqr','sparse_cg','sag','saga'])\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 30/30 [00:00<00:00, 84.07it/s, best loss: -0.7352459216210612]\n",
      "The best parameter tuned on training set is given by :-  {'alpha': 0.34064687620483347, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    reg = Ridge(**params)\n",
    "    return cross_val_score(reg, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best            = fmin(function_to_minimise, ridge_reg_grid, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "best_parameters = space_eval(ridge_reg_grid, best)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.34064687620483347, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='sag', tol=0.001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(**best_parameters)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of determination is:-  0.708046687521789\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('The coefficient of determination is:- ',r2_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion:</b> We did not get the results as expected even after parameter tuning. We will proceed ahead and apply Random Forest regressor on the data to see if we can get better results or not\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_grid = {'n_estimators' : hp.choice('n_estimators',range(5,50)),\n",
    "                      'min_samples_split' : hp.uniform('min_samples_split',0.01,0.95),\n",
    "                      'min_samples_leaf'  : hp.choice('min_samples_leaf',range(1,10)),\n",
    "                      'max_features'      : hp.choice('max_features',['auto','sqrt','log2',None])\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 30/30 [00:02<00:00, 10.09it/s, best loss: -0.8458595332069737]\n",
      "The best parameter tuned on training set is given by :-  {'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 0.024477890823528636, 'n_estimators': 37}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    reg = RandomForestRegressor(**params)\n",
    "    return cross_val_score(reg, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best            = fmin(function_to_minimise, random_forest_grid, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "best_parameters = space_eval(random_forest_grid, best)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=4,\n",
       "                      min_samples_split=0.024477890823528636,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=37,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(**best_parameters)\n",
    "rf_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of determination is:-  0.8595531131950803\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_regressor.predict(X_test)\n",
    "print('The coefficient of determination is:- ',r2_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion:</b> We did see an improvement in the R^2 score from Random Forest Regressor. We will go ahead and try out one more regressor type-Adaboost Regressor\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_reg_grid  = {'n_estimators' : hp.choice('n_estimators',range(5,50)),\n",
    "                      'learning_rate' : hp.uniform('learning_rate',0.05,1.01),\n",
    "                      'loss'          : hp.choice('loss',['linear','square','exponential'])\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 30/30 [00:02<00:00, 11.76it/s, best loss: -0.8408061742218745]\n",
      "The best parameter tuned on training set is given by :-  {'learning_rate': 0.07592731447572787, 'loss': 'linear', 'n_estimators': 7}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    reg = AdaBoostRegressor(**params)\n",
    "    return cross_val_score(reg, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best            = fmin(function_to_minimise, adaboost_reg_grid, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "best_parameters = space_eval(adaboost_reg_grid, best)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=0.07592731447572787,\n",
       "                  loss='linear', n_estimators=7, random_state=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adaboost = AdaBoostRegressor(**best_parameters)\n",
    "model_adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of determination is:-  0.8350157655059629\n"
     ]
    }
   ],
   "source": [
    "print('The coefficient of determination is:- ',r2_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion :</b> Adaboost and Random Forests clearly outperformed the Ridge regressor\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
