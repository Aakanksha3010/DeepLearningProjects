{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emoji\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>How are we Emojifying:</b> We install the library emoji that will enable us to get emojis from a particular representation as stored in the emoji_dictionary. Emoji_dictionary contains the key value representation of a set number of emojis in a dictionary \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key:  0  corresponds to  ‚ù§Ô∏è  this emoji\n",
      "The key:  1  corresponds to  ‚öæ  this emoji\n",
      "The key:  2  corresponds to  üòÑ  this emoji\n",
      "The key:  3  corresponds to  üòû  this emoji\n",
      "The key:  4  corresponds to  üç¥  this emoji\n"
     ]
    }
   ],
   "source": [
    "for keys,values in emoji_dictionary.items():\n",
    "    print('The key: ',keys,' corresponds to ' ,emoji.emojize(str(values),use_aliases=True),' this emoji')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Loading train and test data:</b> We will be loading the train and test data over here and hence we don't need to perform any train test split later. The train and test datasets will have 2 columns. The first column contains a particular sentence and the second column contains the emoji-keys associated with the sentence.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train             = pd.read_csv('train_emoji.csv',header=None,usecols =[0,1])\n",
    "X_train,Y_train      = df_train[0].values, df_train[1].values\n",
    "df_test              = pd.read_csv('tesss.csv',header=None,usecols =[0,1])\n",
    "X_test, Y_test       = df_test[0].values, df_test[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data looks like this \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1\n",
       "0           never talk to me again  3\n",
       "1  I am proud of your achievements  2\n",
       "2   It is the worst day in my life  3\n",
       "3                 Miss you so much  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The train data looks like this ')\n",
    "df_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Visualizing data with Emojis :</b> We will visualize the given data along with the Emojis assigned to them \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We create a function to access the emoji using its key \n"
     ]
    }
   ],
   "source": [
    "print('We create a function to access the emoji using its key ')\n",
    "f_access_emoji      = lambda x: emoji.emojize(emoji_dictionary[str(x)], use_aliases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We consider few random samples and print the statement and the emoji it will follow as below:- \n",
      "I want to go play ‚öæ\n",
      "we made it üòÑ\n",
      "I am so impressed by your dedication to this project üòÑ\n"
     ]
    }
   ],
   "source": [
    "print('We consider few random samples and print the statement and the emoji it will follow as below:- ')\n",
    "print(X_train[9],f_access_emoji(Y_train[9]))\n",
    "print(X_train[40],f_access_emoji(Y_train[40]))\n",
    "print(X_train[80],f_access_emoji(Y_train[80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Loading Pre trained Glove embeddings:</b> We will now load pre trained word embeddings \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+'\\\\glove.6B\\\\glove.6B.'+str(50)+'d.txt'\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "words = set()\n",
    "with open(path,encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word   = values[0]\n",
    "        words.add(word)\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "#     i = 1\n",
    "#     words_to_index = {}\n",
    "#     index_to_words = {}\n",
    "#     for w in sorted(words):\n",
    "#         words_to_index[w] = i\n",
    "#         index_to_words[i] = w\n",
    "#         i = i + 1\n",
    "        \n",
    "print('Found %s word vectors.' % len(word2vec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Averaging vector representation of a sentence:</b> We will average out the vector representation of a sentence to get the vector representation having values between 0 and 1\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    words = sentence.lower().split()\n",
    "    avg = np.zeros(50,)\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg = avg/len(words)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x : (np.exp(x - np.max(x)))/(np.exp(x - np.max(x))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Predicting Emojis:</b> Here we predict the probability of each emoji and return them in form of a list \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, W, b, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data containing sentences, numpy array of shape (m, None)\n",
    "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
    "    \n",
    "    Returns:\n",
    "    pred -- numpy array of shape (m, 1) with your predictions\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    pred = np.zeros((m, 1))\n",
    "    \n",
    "    for j in range(m):                       # Loop over training examples\n",
    "        \n",
    "        # Split jth test example (sentence) into list of lower case words\n",
    "        words = X[j].lower().split()\n",
    "        \n",
    "        # Average words' vectors\n",
    "        avg = np.zeros((50,))\n",
    "        for w in words:\n",
    "            avg += word_to_vec_map[w]\n",
    "        avg = avg/len(words)\n",
    "\n",
    "        # Forward propagation\n",
    "        Z = np.dot(W, avg) + b\n",
    "        A = softmax(Z)\n",
    "        pred[j] = np.argmax(A)\n",
    "        \n",
    "    print(\"Accuracy: \"  + str(np.mean((pred[:] == Y.reshape(Y.shape[0],1)[:]))))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \"\"\"\n",
    "    Model to train word vector representations in numpy.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    m = Y.shape[0]                         \n",
    "    n_y = 5                                \n",
    "    n_h = 50                               \n",
    "    \n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    Y_oh = np.eye(5)[Y.reshape(-1)]\n",
    "    \n",
    "    for t in range(num_iterations):                       \n",
    "        for i in range(m):                                \n",
    "            avg = sentence_to_avg(X[i],word_to_vec_map)\n",
    "\n",
    "            z = W.dot(avg)+b\n",
    "            a = softmax(z)\n",
    "            \n",
    "            cost = -np.sum(np.multiply(Y_oh[i],np.log(a)))\n",
    "            \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "            \n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Training a model:</b> Here we train the model defined above to get the results needed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.9520498647328826\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818659533625\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.0445636922039511\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.034322673638104054\n",
      "Accuracy: 0.9696969696969697\n",
      "Epoch: 400 --- cost = 0.02906976766810495\n",
      "Accuracy: 0.9772727272727273\n",
      "Epoch: 500 --- cost = 0.02566924985114963\n",
      "Accuracy: 0.9772727272727273\n",
      "Epoch: 600 --- cost = 0.023182173795051348\n",
      "Accuracy: 0.9772727272727273\n",
      "Epoch: 700 --- cost = 0.021228282746351104\n",
      "Accuracy: 0.9848484848484849\n",
      "Epoch: 800 --- cost = 0.019625903386799655\n",
      "Accuracy: 0.9848484848484849\n",
      "Epoch: 900 --- cost = 0.01827744285213552\n",
      "Accuracy: 0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word2vec,num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9848484848484849\n",
      "Test set:\n",
      "Accuracy: 0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word2vec)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Actual Implementation with Sentences:</b> Here we are going to feed our model with some sentences and the outcome(emojis) and expect to get a similar output\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\",\"Nice shot played\",\n",
    "                           \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [1],[4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i adore you ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol üòÑ\n",
      "lets play with a ball ‚öæ\n",
      "Nice shot played ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy üòû\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_my_sentences)):\n",
    "    print(X_my_sentences[i],f_access_emoji(str(int(pred[i][0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
