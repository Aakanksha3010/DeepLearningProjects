{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import *\n",
    "import hyperopt\n",
    "from hyperopt import *\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Loading the data:</b> We load the data from the mentioned path\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_of_input_file = r'D:\\kaggle_trials\\graduate-admissions\\Admission_Predict_Ver1.1.csv'\n",
    "df                 = pd.read_csv(path_of_input_file)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Categorical and Numerical Columns Identification:</b> We identify categorical and numerical columns from the data. We do set a threshold that if any categorical value is classified as numerical, then it has to be classified back to categorical if the number of distinct values of that column in the dataframe is less than 10 \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_needed           = list(df.columns)\n",
    "cols_needed           = cols_needed[:len(cols_needed)-1]\n",
    "\n",
    "possible_numeric_cols = list(df._get_numeric_data().columns)\n",
    "possible_numeric_cols.remove('Chance of Admit ','Serial No.')\n",
    "\n",
    "categorical_columns   = list(set(cols_needed)- set(possible_numeric_cols))\n",
    "\n",
    "numerical_columns     = []\n",
    "for i in range(len(possible_numeric_cols)):\n",
    "    col_name  = possible_numeric_cols[i]\n",
    "    if len(df[col_name].unique())<10:\n",
    "        categorical_columns.append(col_name)\n",
    "    else:\n",
    "        numerical_columns.append(col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Encoding and Feature Scaling:</b> We do the one hot encoding of categorical values and scale(by using MinMaxScaler) the numerical values to get the final feature matrix X. Subseqently, we consider the SalePrice column to be our target variable\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe                  = OneHotEncoder()\n",
    "scalar               = MinMaxScaler()\n",
    "encoded_matrix       = ohe.fit_transform(df[categorical_columns])\n",
    "scaled_matrix        = scalar.fit_transform(df[numerical_columns])\n",
    "X_complete_matrix    = scipy.sparse.hstack((encoded_matrix,scaled_matrix)).A\n",
    "Y                    = scalar.fit_transform(df[['Chance of Admit ']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Train Test split:</b> We perform train test split on the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_complete_matrix, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Parameter Grid and tuning :</b> We set up the grid of values for parameter tuning \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg_grid  = {'alpha' : hp.uniform('alpha',0.01,5),\n",
    "                      'precompute' : hp.choice('precompute',[True,False])\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 30/30 [00:00<00:00, 205.33it/s, best loss: -0.08091812155801115]\n",
      "The best parameter tuned on training set is given by :-  {'alpha': 0.049550797650968814, 'precompute': False}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    reg = Lasso(**params)\n",
    "    return cross_val_score(reg, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best            = fmin(function_to_minimise, lasso_reg_grid, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "best_parameters = space_eval(lasso_reg_grid, best)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.049550797650968814, copy_X=True, fit_intercept=True,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Lasso(**best_parameters)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of determination is:-  -101.73823153940464\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('The coefficient of determination is:- ',r2_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion :</b> LASSO gave a very bad fit to the data. We can clearly see that RSS wa higher than TSS resulting in negative Coefficient of determination. We move ahead and try to fit a random forest regressor on the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_grid = {'n_estimators' : hp.choice('n_estimators',range(5,50)),\n",
    "                      'min_samples_split' : hp.uniform('min_samples_split',0.01,0.95),\n",
    "                      'min_samples_leaf'  : hp.choice('min_samples_leaf',range(1,10)),\n",
    "                      'max_features'      : hp.choice('max_features',['auto','sqrt','log2',None])\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 30/30 [00:02<00:00, 10.34it/s, best loss: -0.8222914287771547]\n",
      "The best parameter tuned on training set is given by :-  {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 0.011695696160138769, 'n_estimators': 42}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    reg = RandomForestRegressor(**params)\n",
    "    return cross_val_score(reg, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best            = fmin(function_to_minimise, random_forest_grid, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "best_parameters = space_eval(random_forest_grid, best)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=3,\n",
       "                      min_samples_split=0.011695696160138769,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=42,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(**best_parameters)\n",
    "rf_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of determination is:-  0.8065497749146603\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_regressor.predict(X_test)\n",
    "print('The coefficient of determination is:- ',r2_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Random Forest Conclusion:</b> Random Forest gave a relative better fit as compared to Lasso\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors_grid  = {'n_neighbors' : hp.choice('n_neighbors',range(5,50)),\n",
    "                      'weights' : hp.choice('wrights',['uniform','distance']),\n",
    "                      'algorithm'  : hp.choice('algorithm',['auto','ball_tree','kd_tree','brute']),\n",
    "                      'leaf_size' : hp.choice('leaf_size',range(20,90)),\n",
    "                     'metric'      : hp.choice('metric',['euclidean','manhattan','chebyshev','minkowski'])\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 30/30 [00:00<00:00, 75.98it/s, best loss: -0.7245810446250394]\n",
      "The best parameter tuned on training set is given by :-  {'algorithm': 'ball_tree', 'leaf_size': 56, 'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    reg = KNeighborsRegressor(**params)\n",
    "    return cross_val_score(reg, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best            = fmin(function_to_minimise, k_neighbors_grid, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "best_parameters = space_eval(k_neighbors_grid, best)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='ball_tree', leaf_size=56, metric='manhattan',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                    weights='distance')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knbrs_reg = KNeighborsRegressor(**best_parameters)\n",
    "knbrs_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of determination is:-  0.5868586691761426\n"
     ]
    }
   ],
   "source": [
    "y_pred = knbrs_reg.predict(X_test)\n",
    "print('The coefficient of determination is:- ',r2_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>kneighbors Conclusion:</b> We still got better results than LASSO but Random Forest still remains the better model to fit in our scenario\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
