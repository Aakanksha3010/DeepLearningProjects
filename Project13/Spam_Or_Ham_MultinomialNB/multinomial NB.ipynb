{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "import hyperopt\n",
    "from hyperopt import *\n",
    "from hyperopt import fmin, tpe, hp, space_eval\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Loading dataset:</b> We load the dataset and rename certain columns to be used in our analysis\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               data\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_of_input_file = 'D:\\\\kaggle_trials\\\\sms-spam-collection-dataset\\\\spam.csv'\n",
    "df                 = pd.read_csv(path_of_input_file,encoding='ISO-8859-1')\n",
    "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "df.columns = ['labels', 'data']\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Imbalance check:</b> We can clearly see that the data is imbalanced because there will be more usual mails than spam mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of labels are  2\n"
     ]
    }
   ],
   "source": [
    "num_labels = df['labels'].unique()\n",
    "print('The number of labels are ',len(num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of  ham  labels are :-  4825\n",
      "The number of  spam  labels are :-  747\n",
      "We dont have a balanced dataset and hence we need to perform imbalanced dataset handling\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(num_labels)):\n",
    "    print('The number of ', num_labels[i] ,' labels are :- ',len(df[df['labels']==num_labels[i]]))\n",
    "print('We dont have a balanced dataset and hence we need to perform imbalanced dataset handling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Label Binarizing:</b> We binarize the labels to integers making it easy to feed into the model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb           = LabelBinarizer()\n",
    "Y            = lb.fit_transform(df['labels'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Text Preprocessing:</b> We preprocess the text data by removing punctuations and converting every word to lowercase. Also we create a feature matrix X by using Tf-Idf vectorizer. We used Tf-idf because there are some words people use in usual sms conversations that may not have any word embeddings associated with them\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(statement):\n",
    "    punc_removed_statement = \"\".join(l for l in statement if l not in string.punctuation)\n",
    "    splitting2words        = punc_removed_statement.split()\n",
    "    lower_cased_statement  = \" \".join(word.lower() for word in splitting2words)\n",
    "    return lower_cased_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_data']= df['data'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(decode_error='ignore')\n",
    "X = tfidf.fit_transform(df['preprocessed_data'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Removing Imbalance :</b> Our data is balanced now after applying SMOTE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm           = SMOTE(random_state=42)\n",
    "X_res, Y_res = sm.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples before Oversampling is  747\n",
      "Negative examples before Oversampling is  4825\n",
      "\n",
      "\n",
      "Positive examples after Oversampling is  4825\n",
      "Negative examples after Oversampling is  4825\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Positive examples before Oversampling is ', sum(Y == [1])[0])\n",
    "print('Negative examples before Oversampling is ', sum(Y == [0])[0])\n",
    "print('\\n')\n",
    "print('Positive examples after Oversampling is ', sum(Y_res == [1]))\n",
    "print('Negative examples after Oversampling is ', sum(Y_res == [0]))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Train test split:</b> We create the train test split of the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, Y_res, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Hyper parameter grid:</b> We now set the grid for tuning the hyper parameters associated with the model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_grid = {'alpha' : hp.uniform('alpha',0.5,5),\n",
    "                   'fit_prior'     : hp.choice('fit_prior',[True,False])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 500/500 [00:06<00:00, 75.32it/s, best loss: -0.9862334199996453]\n",
      "The best parameter tuned on training set is given by :-  {'alpha': 0.5031703617001609, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = MultinomialNB(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "\n",
    "def function_to_minimise(params):\n",
    "    accuracy = hyperopt_train_test(params)\n",
    "    return {'loss': -1*accuracy, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials          = Trials()\n",
    "best            = fmin(function_to_minimise, multinomial_grid, algo=tpe.suggest, max_evals=500, trials=trials)\n",
    "best_parameters = space_eval(multinomial_grid, best)\n",
    "print('The best parameter tuned on training set is given by :- ',best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Final Results and Model fitting:</b> We finally fit the model with the tuned hyper parameters and present a classification report as our analysis \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.5031703617001609, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB(**best_parameters)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1614\n",
      "           1       0.99      0.99      0.99      1571\n",
      "\n",
      "    accuracy                           0.99      3185\n",
      "   macro avg       0.99      0.99      0.99      3185\n",
      "weighted avg       0.99      0.99      0.99      3185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
