{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RoucZE1hjrP9",
    "outputId": "15cb0e2c-cc58-4a6e-abad-4f34976dbcdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, CuDNNLSTM, Permute, Dropout, BatchNormalization, add, dot, concatenate\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Preprocessing Functions:</b> We create some basic preprocessing functions related to text like tokenizing the text, parsing stories and vectorizing them in the next few command lines.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJRZ72LZjwUS"
   },
   "outputs": [],
   "source": [
    "def tokenize(sent): ## splitting the text in tokens including punctuation\n",
    "    return [x.strip() for x in re.split('(\\W+)? ', sent) if (x!=None and x.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tA73SsXyj-Z0"
   },
   "outputs": [],
   "source": [
    "def parse_stories(lines, only_supporting=False):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        id, line = line.split(' ', 1)\n",
    "        id = int(id)\n",
    "        if id == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            if only_supporting:\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3h6Uk4akAFp"
   },
   "outputs": [],
   "source": [
    "def get_stories(file, only_supporting=False, max_length=None):\n",
    "    data = parse_stories(file, only_supporting=only_supporting)\n",
    "    flat = lambda data: reduce(lambda i, j: i + j, data)\n",
    "    data = [(flat(story), question, answer) for story, question, answer in data if not max_length or len(flat(story)) < max_length]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDpb6wNMkCQc"
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_id, story_maxlen, question_maxlen):\n",
    "    X = []\n",
    "    Q = []\n",
    "    Y = []\n",
    "    for story, question, answer in data:\n",
    "        x = [word_id[i] for i in story]\n",
    "        q = [word_id[i] for i in question]\n",
    "        # Index 0 is reserved\n",
    "        y = np.zeros(len(word_id) + 1)\n",
    "        y[word_id[answer]] = 1\n",
    "        X.append(x)\n",
    "        Q.append(q)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X, maxlen=story_maxlen), pad_sequences(Q, maxlen=question_maxlen), np.array(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Data Load:</b> Since the notebook was developed in collab, I was able to extract the tar_file from the location given else I have to download it in my local machine and extract from there\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Z9yugRD4kD5M",
    "outputId": "32193333-109a-4a80-a2d7-12f732ce7c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
      "11747328/11745123 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "tar_file = tarfile.open(get_file('babi-tasks-v1-2.tar.gz',\n",
    "                                 origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Data to pick:</b> From the different set of Stories, Questions and Answers, we select the ones we will be using for training and prediction \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2u0PFUzTkLmd"
   },
   "outputs": [],
   "source": [
    "challenges = {\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt', # QA1 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt', # QA2 with 10,000 samples\n",
    "    'list_sets':'tasks_1-20_v1-2/en-10k/qa8_lists-sets_{}.txt'\n",
    "}\n",
    "challenge_type = 'list_sets'\n",
    "challenge = challenges[challenge_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Train and test files:</b> We select the train and test files from the loaded files and then find the actual size of the train and test data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3VMq2YGkP3x"
   },
   "outputs": [],
   "source": [
    "train_file    = tar_file.extractfile(challenge.format('train'))\n",
    "test_file     = tar_file.extractfile(challenge.format('test'))\n",
    "vector_train  = train_file.readlines()\n",
    "vector_test   = test_file.readlines()\n",
    "train_stories = get_stories(vector_train)\n",
    "test_stories  = get_stories(vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6mAw5RcmkXlC",
    "outputId": "a0573dee-1611-48e4-c7e6-2908bc6118a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples in train stories is :-  10000\n",
      "The number of samples in test stories is  :-  1000\n"
     ]
    }
   ],
   "source": [
    "print('The number of samples in train stories is :- ',len(train_stories))\n",
    "print('The number of samples in test stories is  :- ',len(test_stories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Setting Up Vocabulary:</b> We set up the vocabulary for the train and test stories\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "wq-fPGK0ka7q",
    "outputId": "81dcdc0a-004d-4339-f5f3-6305be5d587c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'Daniel', 'John', 'Mary', 'Sandra', 'What', 'apple', 'apple,football', 'apple,football,milk', 'apple,milk', 'apple,milk,football', 'apple.', 'back', 'bathroom.', 'bedroom.', 'carrying', 'discarded', 'down', 'dropped', 'football', 'football,apple', 'football,apple,milk', 'football,milk', 'football,milk,apple', 'football.', 'garden.', 'got', 'grabbed', 'hallway.', 'is', 'journeyed', 'kitchen.', 'left', 'milk', 'milk,apple', 'milk,apple,football', 'milk,football', 'milk,football,apple', 'milk.', 'moved', 'nothing', 'office.', 'picked', 'put', 'the', 'there.', 'to', 'took', 'travelled', 'up', 'went']\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for story, question, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + question + [answer])\n",
    "vocab = sorted(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2ZHpzsOik6Iw",
    "outputId": "486de170-33a6-479c-f7e1-6d4db55edcde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ah0P2fVFkdTe"
   },
   "outputs": [],
   "source": [
    "story_maxlen = max(map(len, (s for s, _, _ in train_stories + test_stories)))\n",
    "question_maxlen = max(map(len, (s for _, s, _ in train_stories + test_stories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "vXvEFTU2kgMG",
    "outputId": "53141c6a-0e45-49dc-89fd-eec5ebca7205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story max length: 300\n",
      "Question max length: 5\n"
     ]
    }
   ],
   "source": [
    "print('Story max length:', story_maxlen)\n",
    "print('Question max length:', question_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ua6wYm1mkhp1",
    "outputId": "a2e0ec61-f7b4-419a-ba90-ec296ad307f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'?': 1, 'Daniel': 2, 'John': 3, 'Mary': 4, 'Sandra': 5, 'What': 6, 'apple': 7, 'apple,football': 8, 'apple,football,milk': 9, 'apple,milk': 10, 'apple,milk,football': 11, 'apple.': 12, 'back': 13, 'bathroom.': 14, 'bedroom.': 15, 'carrying': 16, 'discarded': 17, 'down': 18, 'dropped': 19, 'football': 20, 'football,apple': 21, 'football,apple,milk': 22, 'football,milk': 23, 'football,milk,apple': 24, 'football.': 25, 'garden.': 26, 'got': 27, 'grabbed': 28, 'hallway.': 29, 'is': 30, 'journeyed': 31, 'kitchen.': 32, 'left': 33, 'milk': 34, 'milk,apple': 35, 'milk,apple,football': 36, 'milk,football': 37, 'milk,football,apple': 38, 'milk.': 39, 'moved': 40, 'nothing': 41, 'office.': 42, 'picked': 43, 'put': 44, 'the': 45, 'there.': 46, 'to': 47, 'took': 48, 'travelled': 49, 'up': 50, 'went': 51}\n"
     ]
    }
   ],
   "source": [
    "word2id = dict((w, i + 1) for i, w in enumerate(vocab))\n",
    "print(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ha45M1rDkjXi"
   },
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_stories, word2id, story_maxlen, question_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eDmeqMGklam"
   },
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_stories, word2id, story_maxlen, question_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "dTIpE94okm5S",
    "outputId": "cf4496d3-3b62-4616-b1dc-664b083ae81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_train shape: (10000, 300)\n",
      "inputs_test shape: (1000, 300)\n"
     ]
    }
   ],
   "source": [
    "print('inputs_train shape:', inputs_train.shape)\n",
    "print('inputs_test shape:', inputs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Mwy0k8RvkpFN",
    "outputId": "687b7f37-fa14-4f24-8dc1-a821f79ec27e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries_train shape: (10000, 5)\n",
      "queries_test shape: (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "print('queries_train shape:', questions_train.shape)\n",
    "print('queries_test shape:', questions_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "l9pNrw8IkqqV",
    "outputId": "f7d0294e-ec58-40ee-9d0c-f8388ef5ab6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers_train shape: (10000, 52)\n",
      "answers_test shape: (1000, 52)\n"
     ]
    }
   ],
   "source": [
    "print('answers_train shape:', answers_train.shape)\n",
    "print('answers_test shape:', answers_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Memory Module:</b> We create memory module here\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdNZeqGMksFE"
   },
   "outputs": [],
   "source": [
    "story_sequence = Input((story_maxlen,))\n",
    "question = Input((question_maxlen,))\n",
    "\n",
    "# embed the input sequence into a sequence of vectors for the stories\n",
    "input_encoder_s = Sequential()\n",
    "input_encoder_s.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_s.add(Dropout(0.3))\n",
    "\n",
    "# embed the input into a sequence of vectors of size question_maxlen\n",
    "# output: (samples, story_maxlen, question_maxlen)\n",
    "input_encoder_q = Sequential()\n",
    "input_encoder_q.add(Embedding(input_dim=vocab_size, output_dim=question_maxlen))\n",
    "input_encoder_q.add(Dropout(0.3))\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=question_maxlen))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Controller Module:</b> We create controller module here \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lgx0z2ypkumM"
   },
   "outputs": [],
   "source": [
    "# encode input sequence and questions to sequences of dense vectors\n",
    "input_encoded_s = input_encoder_s(story_sequence)\n",
    "input_encoded_q = input_encoder_q(story_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "# compute a 'match' between the first input vector sequence\n",
    "# and the question vector sequence\n",
    "# shape: `(samples, story_maxlen, question_maxlen)`\n",
    "match = dot([input_encoded_s, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_q])  # (samples, story_maxlen, question_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, question_maxlen, story_maxlen)\n",
    "\n",
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "answer = CuDNNLSTM(32)(answer)  # (samples, 32)\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = BatchNormalization()(answer)\n",
    "\n",
    "output = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "output = Activation('softmax')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_UwZkVFlD6e"
   },
   "outputs": [],
   "source": [
    "model = Model([story_sequence, question], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "9EZhjELvlGIX",
    "outputId": "697a22b1-50bf-475e-dfd9-dd4c9c83aea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       multiple             3328        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 5, 64)        3328        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 300, 5)       0           sequential_5[1][0]               \n",
      "                                                                 sequential_7[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 300, 5)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       multiple             260         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 300, 5)       0           activation_1[0][0]               \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 5, 300)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 364)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_7[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        (None, 32)           50944       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32)           128         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 52)           1716        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 52)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 59,704\n",
      "Trainable params: 59,640\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "4iNEVHk4lHmC",
    "outputId": "41043cc9-822f-4d81-db9d-b87de8448901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(0.005), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Training the model:</b> We train the model using the given set of hyper parameters and parameters. I have not parameter tuned the observations because of lack of system memory to do that.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7OwIwDWelKgm",
    "outputId": "3d898c89-db02-4d86-fb75-a81a308756b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 8s 846us/step - loss: 2.5594 - acc: 0.3024 - val_loss: 1.5814 - val_acc: 0.4030\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 1.5021 - acc: 0.4212 - val_loss: 1.4786 - val_acc: 0.4300\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 1.3942 - acc: 0.5066 - val_loss: 1.5844 - val_acc: 0.3510\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 1.2688 - acc: 0.5666 - val_loss: 1.2217 - val_acc: 0.5310\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 1.1119 - acc: 0.6365 - val_loss: 0.9645 - val_acc: 0.7020\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.9427 - acc: 0.7089 - val_loss: 0.8421 - val_acc: 0.7330\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 0.8582 - acc: 0.7311 - val_loss: 0.7606 - val_acc: 0.7460\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 1s 128us/step - loss: 0.8099 - acc: 0.7429 - val_loss: 0.7500 - val_acc: 0.7410\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.7915 - acc: 0.7428 - val_loss: 0.6972 - val_acc: 0.7560\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 0.7546 - acc: 0.7496 - val_loss: 0.6643 - val_acc: 0.7710\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.7275 - acc: 0.7560 - val_loss: 0.6732 - val_acc: 0.7590\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 0.7056 - acc: 0.7581 - val_loss: 0.6590 - val_acc: 0.7650\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 1s 128us/step - loss: 0.7102 - acc: 0.7525 - val_loss: 0.7006 - val_acc: 0.7400\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.6871 - acc: 0.7649 - val_loss: 0.6379 - val_acc: 0.7660\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.6805 - acc: 0.7640 - val_loss: 0.6584 - val_acc: 0.7600\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.6646 - acc: 0.7661 - val_loss: 0.6156 - val_acc: 0.7640\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.6587 - acc: 0.7711 - val_loss: 0.6528 - val_acc: 0.7700\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.6554 - acc: 0.7657 - val_loss: 0.6370 - val_acc: 0.7600\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.6464 - acc: 0.7690 - val_loss: 0.6552 - val_acc: 0.7530\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.6376 - acc: 0.7702 - val_loss: 0.6681 - val_acc: 0.7550\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.6225 - acc: 0.7752 - val_loss: 0.6254 - val_acc: 0.7670\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.6092 - acc: 0.7776 - val_loss: 0.6227 - val_acc: 0.7570\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.6065 - acc: 0.7730 - val_loss: 0.6299 - val_acc: 0.7590\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.6020 - acc: 0.7784 - val_loss: 0.6240 - val_acc: 0.7650\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.5935 - acc: 0.7749 - val_loss: 0.6285 - val_acc: 0.7640\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.5931 - acc: 0.7788 - val_loss: 0.5971 - val_acc: 0.7650\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.5753 - acc: 0.7805 - val_loss: 0.6319 - val_acc: 0.7470\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.5716 - acc: 0.7875 - val_loss: 0.6157 - val_acc: 0.7560\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.5765 - acc: 0.7866 - val_loss: 0.6132 - val_acc: 0.7730\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.5544 - acc: 0.7900 - val_loss: 0.6302 - val_acc: 0.7720\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.5414 - acc: 0.7953 - val_loss: 0.6074 - val_acc: 0.7770\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 0.5351 - acc: 0.7982 - val_loss: 0.6066 - val_acc: 0.7700\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 1s 128us/step - loss: 0.5253 - acc: 0.7989 - val_loss: 0.6934 - val_acc: 0.7700\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.5206 - acc: 0.8033 - val_loss: 0.5845 - val_acc: 0.7760\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 1s 128us/step - loss: 0.5090 - acc: 0.8072 - val_loss: 0.5775 - val_acc: 0.7790\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.5023 - acc: 0.8120 - val_loss: 0.5815 - val_acc: 0.7850\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.4912 - acc: 0.8147 - val_loss: 0.5766 - val_acc: 0.7750\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.4681 - acc: 0.8268 - val_loss: 0.5925 - val_acc: 0.7880\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 0.4697 - acc: 0.8245 - val_loss: 0.5694 - val_acc: 0.8030\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.4622 - acc: 0.8344 - val_loss: 0.5290 - val_acc: 0.8060\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.4418 - acc: 0.8431 - val_loss: 0.5462 - val_acc: 0.8120\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.4283 - acc: 0.8460 - val_loss: 0.5147 - val_acc: 0.8220\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.4141 - acc: 0.8507 - val_loss: 0.5572 - val_acc: 0.8120\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.4024 - acc: 0.8566 - val_loss: 0.5607 - val_acc: 0.8280\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.3858 - acc: 0.8630 - val_loss: 0.5547 - val_acc: 0.8290\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.3738 - acc: 0.8645 - val_loss: 0.5191 - val_acc: 0.8290\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.3560 - acc: 0.8728 - val_loss: 0.5540 - val_acc: 0.8210\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.3692 - acc: 0.8682 - val_loss: 0.5125 - val_acc: 0.8300\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.3475 - acc: 0.8739 - val_loss: 0.5256 - val_acc: 0.8310\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.3377 - acc: 0.8793 - val_loss: 0.5555 - val_acc: 0.8300\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.3466 - acc: 0.8768 - val_loss: 0.5737 - val_acc: 0.8290\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.3223 - acc: 0.8865 - val_loss: 0.5475 - val_acc: 0.8330\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.3193 - acc: 0.8874 - val_loss: 0.5363 - val_acc: 0.8380\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.3012 - acc: 0.8952 - val_loss: 0.5964 - val_acc: 0.8350\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.3036 - acc: 0.8906 - val_loss: 0.5771 - val_acc: 0.8290\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.2971 - acc: 0.8937 - val_loss: 0.5865 - val_acc: 0.8340\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.2990 - acc: 0.8953 - val_loss: 0.5449 - val_acc: 0.8430\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.2728 - acc: 0.9001 - val_loss: 0.5557 - val_acc: 0.8440\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.2677 - acc: 0.9014 - val_loss: 0.5784 - val_acc: 0.8300\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.2728 - acc: 0.9042 - val_loss: 0.5767 - val_acc: 0.8300\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.2620 - acc: 0.9063 - val_loss: 0.5782 - val_acc: 0.8410\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.2487 - acc: 0.9107 - val_loss: 0.6051 - val_acc: 0.8410\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.2528 - acc: 0.9075 - val_loss: 0.6234 - val_acc: 0.8420\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.2422 - acc: 0.9111 - val_loss: 0.6346 - val_acc: 0.8310\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.2441 - acc: 0.9129 - val_loss: 0.6627 - val_acc: 0.8390\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.2388 - acc: 0.9199 - val_loss: 0.6843 - val_acc: 0.8270\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.2492 - acc: 0.9131 - val_loss: 0.6245 - val_acc: 0.8360\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.2089 - acc: 0.9254 - val_loss: 0.6150 - val_acc: 0.8440\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.2355 - acc: 0.9152 - val_loss: 0.6666 - val_acc: 0.8320\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.2177 - acc: 0.9219 - val_loss: 0.7091 - val_acc: 0.8400\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.2278 - acc: 0.9208 - val_loss: 0.6711 - val_acc: 0.8370\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.2138 - acc: 0.9242 - val_loss: 0.6339 - val_acc: 0.8320\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.2084 - acc: 0.9283 - val_loss: 0.7163 - val_acc: 0.8290\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1967 - acc: 0.9288 - val_loss: 0.6721 - val_acc: 0.8370\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1936 - acc: 0.9297 - val_loss: 0.6769 - val_acc: 0.8420\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.1884 - acc: 0.9323 - val_loss: 0.7283 - val_acc: 0.8360\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.2014 - acc: 0.9293 - val_loss: 0.7489 - val_acc: 0.8470\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.1808 - acc: 0.9348 - val_loss: 0.7293 - val_acc: 0.8290\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.2009 - acc: 0.9284 - val_loss: 0.6966 - val_acc: 0.8300\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1863 - acc: 0.9318 - val_loss: 0.7705 - val_acc: 0.8440\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1867 - acc: 0.9349 - val_loss: 0.7315 - val_acc: 0.8290\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.1810 - acc: 0.9340 - val_loss: 0.6679 - val_acc: 0.8400\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.1699 - acc: 0.9394 - val_loss: 0.7139 - val_acc: 0.8320\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 0.1983 - acc: 0.9291 - val_loss: 0.6934 - val_acc: 0.8270\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1640 - acc: 0.9400 - val_loss: 0.7079 - val_acc: 0.8240\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.1569 - acc: 0.9421 - val_loss: 0.7125 - val_acc: 0.8360\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1720 - acc: 0.9390 - val_loss: 0.7396 - val_acc: 0.8310\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1615 - acc: 0.9429 - val_loss: 0.7354 - val_acc: 0.8450\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.1711 - acc: 0.9411 - val_loss: 0.6920 - val_acc: 0.8390\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1630 - acc: 0.9431 - val_loss: 0.7461 - val_acc: 0.8370\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1558 - acc: 0.9463 - val_loss: 0.7715 - val_acc: 0.8400\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.1616 - acc: 0.9437 - val_loss: 0.8189 - val_acc: 0.8380\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.1564 - acc: 0.9436 - val_loss: 0.7761 - val_acc: 0.8320\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1603 - acc: 0.9448 - val_loss: 0.8076 - val_acc: 0.8400\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1515 - acc: 0.9456 - val_loss: 0.7939 - val_acc: 0.8420\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.1499 - acc: 0.9477 - val_loss: 0.8781 - val_acc: 0.8390\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1577 - acc: 0.9441 - val_loss: 0.8382 - val_acc: 0.8340\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1537 - acc: 0.9471 - val_loss: 0.7979 - val_acc: 0.8400\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1358 - acc: 0.9520 - val_loss: 0.8161 - val_acc: 0.8330\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 0.1388 - acc: 0.9509 - val_loss: 0.8299 - val_acc: 0.8310\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1364 - acc: 0.9518 - val_loss: 0.8669 - val_acc: 0.8390\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1322 - acc: 0.9538 - val_loss: 0.9295 - val_acc: 0.8230\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.1650 - acc: 0.9443 - val_loss: 0.8327 - val_acc: 0.8400\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.1346 - acc: 0.9541 - val_loss: 0.8627 - val_acc: 0.8350\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.1478 - acc: 0.9459 - val_loss: 0.8817 - val_acc: 0.8370\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.1305 - acc: 0.9550 - val_loss: 0.8074 - val_acc: 0.8410\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1378 - acc: 0.9516 - val_loss: 0.8005 - val_acc: 0.8350\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 0.1270 - acc: 0.9542 - val_loss: 0.8348 - val_acc: 0.8380\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 1s 125us/step - loss: 0.1349 - acc: 0.9524 - val_loss: 0.8482 - val_acc: 0.8450\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.1287 - acc: 0.9541 - val_loss: 0.7908 - val_acc: 0.8450\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1296 - acc: 0.9541 - val_loss: 0.8743 - val_acc: 0.8380\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.1287 - acc: 0.9564 - val_loss: 0.8413 - val_acc: 0.8370\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 0.1038 - acc: 0.9642 - val_loss: 0.8052 - val_acc: 0.8430\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1120 - acc: 0.9608 - val_loss: 0.8159 - val_acc: 0.8460\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 1s 121us/step - loss: 0.1203 - acc: 0.9563 - val_loss: 0.8508 - val_acc: 0.8370\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.1099 - acc: 0.9612 - val_loss: 0.8733 - val_acc: 0.8360\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 0.1203 - acc: 0.9602 - val_loss: 0.8502 - val_acc: 0.8380\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 0.1397 - acc: 0.9520 - val_loss: 0.8834 - val_acc: 0.8220\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 0.1225 - acc: 0.9567 - val_loss: 0.9064 - val_acc: 0.8390\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 1s 120us/step - loss: 0.1137 - acc: 0.9596 - val_loss: 0.8819 - val_acc: 0.8330\n",
      "CPU times: user 2min 42s, sys: 26.2 s, total: 3min 8s\n",
      "Wall time: 2min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f90fdbfd4a8>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit([inputs_train, questions_train], answers_train,\n",
    "          batch_size=128,\n",
    "          epochs=120,\n",
    "          validation_data=([inputs_test, questions_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOzGuxgUlM_o"
   },
   "outputs": [],
   "source": [
    "model.save('../chatbot_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erCug0lqmXSW"
   },
   "outputs": [],
   "source": [
    "model.load_weights('../chatbot_model.h5')\n",
    "pred = model.predict(([inputs_test, questions_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Answering a question:</b> We now use the trained model to answer a few questions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZ7K4Ro8meg7"
   },
   "outputs": [],
   "source": [
    "n = np.random.randint(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5V8EH0U6mg7p",
    "outputId": "3b73004c-b7a9-4fe9-db97-b727e33b064a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story is: Daniel went to the hallway. Daniel journeyed to the kitchen. Mary went back to the kitchen. Mary took the football there.\n"
     ]
    }
   ],
   "source": [
    "story_list = test_stories[n][0]\n",
    "story =' '.join(word for word in story_list)\n",
    "print(\"Story is:\",story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nmwWcvSKmiwL",
    "outputId": "14175c16-c9f0-46ac-ab11-55bb3b219d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question is:  What is Mary carrying ?\n"
     ]
    }
   ],
   "source": [
    "question_list = test_stories[n][1]\n",
    "question =' '.join(word for word in question_list)\n",
    "print(\"Question is: \", question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "226SBeqImmQG",
    "outputId": "9553eec5-9e1c-464b-cfcc-526db46f6770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual answer is:  football\n"
     ]
    }
   ],
   "source": [
    "answer = test_stories[n][2]\n",
    "print(\"Actual answer is: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjY8r_o5mpH9"
   },
   "outputs": [],
   "source": [
    "max_value = np.argmax(pred[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "MX0DfdLCmsI6",
    "outputId": "5ef8eec3-0690-44fc-c144-7ffacec37c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine answer is:  football\n",
      "Machine says: I am  0.99996567 certain of it\n"
     ]
    }
   ],
   "source": [
    "for key, val in word2id.items():\n",
    "    if val == max_value:\n",
    "        k = key\n",
    "\n",
    "print(\"Machine answer is: \", k)\n",
    "print(\"Machine says: I am \", pred[n][max_value], \"certain of it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JmrV-UTemt0m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "memory_nets_chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
